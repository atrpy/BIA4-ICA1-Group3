{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T05:11:28.939358Z",
     "start_time": "2025-12-10T05:11:27.341137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import visdom\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss"
   ],
   "id": "54e86c5f25c92f4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T05:11:30.250717Z",
     "start_time": "2025-12-10T05:11:30.237927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CommonBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1):        # A regular Block can simply complete two convolution operations\n",
    "        super(CommonBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x                                            #The shortcut for a regular Block is a direct connection and does not require dimensional upscaling or downsampling\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)       # Complete a convolution\n",
    "        x = self.bn2(self.conv2(x))                             # The second convolution does not add the relu activation function\n",
    "\n",
    "        x += identity                                           # Sum of two paths\n",
    "        return F.relu(x, inplace=True)                          # Add an activation function output\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")                         # åˆ›å»ºGPUè¿ç®—çŽ¯å¢ƒ\n",
    "print(device)\n",
    "\n",
    "class SpecialBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(SpecialBlock, self).__init__()\n",
    "        self.change_channel = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.change_channel(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        return F.relu(out, inplace=True)\n",
    "                    # Output convolutional unit\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, classes_num):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.prepare = nn.Sequential(           # The common preprocessing for all Resnets == [batch, 64, 56, 56]\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(            # layer1 is a bit special. Since both the input and output channels are 64, there are two common blocks\n",
    "            CommonBlock(64, 64, stride=1),\n",
    "            CommonBlock(64, 64, stride=1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(            # layer234 is similar. Due to the different input and output channels, there is one SpecialBlock and one CommonBlock\n",
    "            SpecialBlock(64, 128, stride=2),\n",
    "            CommonBlock(128, 128, stride=1)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            SpecialBlock(128, 256, stride=2),\n",
    "            CommonBlock(256, 256, stride=1)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            SpecialBlock(256, 512, stride=2),\n",
    "            CommonBlock(512, 512, stride=1)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))    # Convolution is completed through an adaptive mean pooling == [batch, 512, 1, 1]\n",
    "        self.fc = nn.Sequential(                # The fully connected layer finally used for classification varies flexibly as needed\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prepare(x)         # prepare\n",
    "\n",
    "        x = self.layer1(x)          # 4 conv units\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.pool(x)            # max pooling\n",
    "        x = x.flatten(1)   # flatten x\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "d66666d6ca00f523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T05:12:13.966105Z",
     "start_time": "2025-12-10T05:12:13.938084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# ==== path ====\n",
    "img_dir = 'Dataset Binary'                  # picture file\n",
    "label_file = 'Dataset_Labels.xlsx'          # label file\n",
    "\n",
    "img_dir = 'Dataset Binary'\n",
    "train_csv = 'spine_train_split.csv'\n",
    "test_csv  = 'spine_test_split.csv'\n",
    "save_path = \"./Spine_ResNet18.pth\"\n",
    "# ==== read label ====\n",
    "\n",
    "\n",
    "df = pd.read_excel(label_file)\n",
    "df.columns = ['Spine_Name', 'Spine_Label']\n",
    "\n",
    "# To facilitate indexing, we convert the DataFrame into a dict\n",
    "label_dict = dict(zip(df['Spine_Name'], df['Spine_Label']))\n",
    "\n",
    "# ==== data enforce ====\n",
    "\n",
    "\n",
    "class BinarySpineDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.data = dataframe.reset_index(drop=True)  # The received DataFrame no longer reads the csv\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_map = {\n",
    "            \"Mushroom\": 0,\n",
    "            \"Stubby\": 1,\n",
    "            \"Thin\": 2\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        img_path = os.path.join(self.root_dir, row['Spine_Name'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        label_str = row['Spine_Label']\n",
    "        label = self.label_map[label_str]   # â† Here convert the string to 0/1/2\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# ==== Divide the training set and the test set ====\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df  = pd.read_csv(test_csv)\n",
    "\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((250, 250)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((250, 250)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_dataset = BinarySpineDataset(train_df, img_dir, transform=data_transform[\"train\"])\n",
    "val_dataset   = BinarySpineDataset(val_df,   img_dir, transform=data_transform[\"val\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "7f0f795f25ab8bcd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T05:12:15.878722Z",
     "start_time": "2025-12-10T05:12:15.834115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import visdom\n",
    "from PIL import Image\n",
    "model = ResNet18(classes_num=3)\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import optim\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 30\n",
    "save_path = \"./Spine_ResNet18.pth\"    # The location for saving model weight parameters"
   ],
   "id": "2fd871cbe4bdfde0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T05:15:26.457556Z",
     "start_time": "2025-12-10T05:13:38.175398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a visdom to visualize the training and testing situations\n",
    "viz = visdom.Visdom(env=\"spine_exp\")\n",
    "\n",
    "# Test functions, input models and data reading interfaces\n",
    "def evalute(model, loader):\n",
    "    correct = 0\n",
    "    total = len(loader.dataset)\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # The validation and test processes do not require backpropagation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(x)\n",
    "            prediction = out.argmax(dim=1)\n",
    "        correct += torch.eq(prediction, y).float().sum().item()\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "net = ResNet18(classes_num=3)\n",
    "#net.load_state_dict(torch.load(save_path))          # Continue training using the weights from the last training\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss_function = CrossEntropyLoss()                  # The cross-entropy loss function is used in multi-classification problems\n",
    "\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "global_step = 0\n",
    "EPOCH = 30\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # update loss line\n",
    "        viz.line([loss.item()], [global_step], win='resnet_loss', update='append')\n",
    "        global_step += 1\n",
    "\n",
    "        rate = (step + 1) / len(train_loader)\n",
    "        a = \"*\" * int(rate * 50)\n",
    "        b = \".\" * int((1 - rate) * 50)\n",
    "        print(f\"\\repoch: {epoch+1} train loss: {int(rate*100):3d}% [{a}->{b}] {loss:.4f}\", end=\"\")\n",
    "\n",
    "    # ===== Perform a validation once per epoch =====\n",
    "    test_acc = evalute(net, test_loader)\n",
    "    print(f\"  epoch {epoch+1} test acc: {test_acc:.4f}\")\n",
    "\n",
    "    # ===== keep best model =====\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': best_epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_acc': best_acc\n",
    "        }, save_path)\n",
    "\n",
    "        print(f\"\\nðŸ”¥ Saved best model at epoch {best_epoch}, acc={best_acc:.4f}\")\n",
    "\n",
    "print(\"Finish !\")\n",
    "print(\"Best epoch:\", best_epoch, \" Best Acc:\", best_acc)\n"
   ],
   "id": "8028374f2c884d2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss:  25% [************->.....................................] 1.0377"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 44\u001B[0m\n\u001B[1;32m     42\u001B[0m outputs \u001B[38;5;241m=\u001B[39m net(images)\n\u001B[1;32m     43\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_function(outputs, labels)\n\u001B[0;32m---> 44\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     47\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/wd/lib/python3.8/site-packages/torch/_tensor.py:521\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    513\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    514\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    519\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    520\u001B[0m     )\n\u001B[0;32m--> 521\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/wd/lib/python3.8/site-packages/torch/autograd/__init__.py:289\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    284\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 289\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/wd/lib/python3.8/site-packages/torch/autograd/graph.py:769\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    767\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    770\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    772\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    773\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
